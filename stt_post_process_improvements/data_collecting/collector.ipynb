{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b4e689",
   "metadata": {},
   "source": [
    "# 📘 Instructions: Using `collector.ipynb`\n",
    "\n",
    "> This cell explains what this notebook does, what you need to run it, and the recommended workflow.\n",
    "\n",
    "**What’s inside (at a glance):** This notebook focuses on **YouTube audio download, audio segmentation into WAV snippets, Whisper speech-to-text (optional), tabular metadata handling (CSV)**.\n",
    "\n",
    "## 1) Prerequisites\n",
    "- **Python:** 3.9+ recommended.\n",
    "- **Key Python packages detected:** `pandas, pydub, whisper, yt_dlp`\n",
    "\n",
    "## 2) Setup\n",
    "1. (Optional) Create and activate a virtual environment.\n",
    "2. Install dependencies:\n",
    "   ```bash\n",
    "   pip install pandas pydub whisper yt_dlp\n",
    "   ```\n",
    "3. Ensure input paths and credentials (if any) are configured in the first configuration cell.\n",
    "\n",
    "## 3) How to use this notebook\n",
    "1. **Configure** input/output directories and parameters (e.g., source URLs, segment length).\n",
    "2. **Run Data Collection** (e.g., download audio from YouTube if applicable).\n",
    "3. **Segment/Preprocess Audio** into smaller WAV files (and generate per-segment metadata).\n",
    "4. **(Optional) Transcribe** audio with Whisper and store transcripts.\n",
    "5. **Validate/Export** results (CSV/JSON manifests, WAV files).\n",
    "\n",
    "**Notable functions in this notebook:**\n",
    "```\n",
    "convert_to_wav\n",
    "download_audio\n",
    "flush_accumulator\n",
    "youtube_to_segmented_wavs\n",
    "```\n",
    "\n",
    "## 4) Tips for reliability & reproducibility\n",
    "- Run cells in order (top → bottom).\n",
    "- Keep configuration in one place and document parameter values.\n",
    "- Version outputs (e.g., add timestamps to filenames).\n",
    "- Log important steps and counts (downloaded files, segments created).\n",
    "\n",
    "## 5) Outputs\n",
    "- **Audio segments**: `*.wav` files per segment.\n",
    "- **Manifests/metadata**: CSV/JSON files summarising segments and sources.\n",
    "- **(Optional) Transcripts**: text files or CSV columns with transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5210308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import whisper\n",
    "from pathlib import Path\n",
    "from yt_dlp import YoutubeDL\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462a041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utils:\n",
    "def convert_to_wav(src_path: str, dst_path: str, sr: int = 16000):\n",
    "    AudioSegment.from_file(src_path) \\\n",
    "        .set_frame_rate(sr) \\\n",
    "        .set_channels(1) \\\n",
    "        .export(dst_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d49d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download audio-only + subtitles (VTT)\n",
    "def download_audio(url: str, outdir: str = 'downloads'):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # 1) First grab metadata only\n",
    "    meta_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'skip_download': True,\n",
    "        'writesubtitles': False,\n",
    "        'writeautomaticsub': False,\n",
    "    }\n",
    "    with YoutubeDL(meta_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': f'{outdir}/%(id)s.%(ext)s',\n",
    "        'quiet': True,\n",
    "        'subtitlesformat': 'vtt',\n",
    "    }\n",
    "\n",
    "    print(f\"[download] audio: {ydl_opts['format']}\")\n",
    "    \n",
    "    # 4) Download audio\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "\n",
    "    vid_id = info['id']\n",
    "    ext = info.get('ext')  \n",
    "    audio_file = Path(outdir) / f\"{vid_id}.{ext}\"\n",
    "\n",
    "    return str(audio_file), info\n",
    "\n",
    "# 2. Convert to WAV @ 16 kHz mono\n",
    "def convert_to_wav(src_path: str, dst_path: str, sr: int = 16000):\n",
    "    AudioSegment.from_file(src_path) \\\n",
    "        .set_frame_rate(sr) \\\n",
    "        .set_channels(1) \\\n",
    "        .export(dst_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper configuration, please check the whisper documentation for more details: https://github.com/openai/whisper\n",
    "model_size = \"medium.en\"\n",
    "device = \"cpu\"\n",
    "\n",
    "# load the Whisper model\n",
    "whisper_model = whisper.load_model(model_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a58a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_to_segmented_wavs(url, lang='en', outdir='downloads', min_limit=6, pad=0.05):\n",
    "    audio_src, info = download_audio(url, outdir)\n",
    "    wav_path = Path(outdir) / f\"{info['id']}.wav\"\n",
    "    convert_to_wav(audio_src, wav_path, sr=16000)\n",
    "\n",
    "    # 2. whisper transcript\n",
    "    stt_result = whisper.transcribe(whisper_model, wav_path)[\"text\"]\n",
    "    segments = stt_result.segments\n",
    "    print(stt_result)\n",
    "\n",
    "    # 3. slice with ffmpeg\n",
    "    seg_dir = Path(outdir) / 'segments'\n",
    "    seg_dir.mkdir(exist_ok=True)\n",
    "    rows = []\n",
    "    \n",
    "    segment_counter = 1\n",
    "    acc_seg = None\n",
    "    \n",
    "    def flush_accumulator(acc, counter):\n",
    "        \"\"\"\n",
    "        Given acc = {'start', 'end', 'text'}, cut with ffmpeg (using pad),\n",
    "        append one row to `rows`, and increment counter.\n",
    "        \n",
    "        Returns: updated counter (counter+1).\n",
    "        \"\"\"\n",
    "        start_ts = acc['start']\n",
    "        end_ts   = acc['end']\n",
    "        transcript = acc['text']\n",
    "        \n",
    "        # padded cut times (clamped at 0 on the left)\n",
    "        padded_start = max(0, start_ts - pad)\n",
    "        padded_end   = end_ts + pad\n",
    "        \n",
    "        out_file = seg_dir / f\"{info['id']}_seg{counter:03d}.wav\"\n",
    "        subprocess.run([\n",
    "            'ffmpeg', '-y',\n",
    "            '-i', str(wav_path),\n",
    "            '-ss', f\"{padded_start:.3f}\",\n",
    "            '-to', f\"{padded_end:.3f}\",\n",
    "            '-ar', '16000',\n",
    "            '-ac', '1',\n",
    "            str(out_file)\n",
    "        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        \n",
    "        rows.append({\n",
    "            'segment_filename': out_file.name,\n",
    "            'start': start_ts,\n",
    "            'end': end_ts,\n",
    "            'transcript': transcript,\n",
    "            'video_id': info.get('id'),\n",
    "            'video_title': info.get('title'),\n",
    "            'video_url': info.get('webpage_url'),\n",
    "        })\n",
    "        return counter + 1\n",
    "    \n",
    "    # 4. iterate through Whisper segments, merging below‐limit ones\n",
    "    for seg in segments:        \n",
    "        if acc_seg is None:\n",
    "            acc_seg = {'start': seg.start, 'end': seg.end, 'text': seg.text.strip()}\n",
    "            continue\n",
    "\n",
    "        # always extend\n",
    "        acc_seg['end']  = seg.end\n",
    "        acc_seg['text'] = f\"{acc_seg['text'].rstrip()} {seg.text.lstrip()}\"\n",
    "\n",
    "        if (acc_seg['end'] - acc_seg['start']) >= min_limit:\n",
    "            segment_counter = flush_accumulator(acc_seg, segment_counter)\n",
    "            acc_seg = None\n",
    "    \n",
    "    # 5. After loop, if there's still leftover acc_seg, flush it regardless of duration\n",
    "    if acc_seg is not None:\n",
    "        segment_counter = flush_accumulator(acc_seg, segment_counter)\n",
    "        acc_seg = None\n",
    "    \n",
    "    # 6. Write CSV and return\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = Path(outdir) / f\"segments_metadata_{info['id']}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return df, seg_dir, csv_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571042d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please insert the URL of the YouTube video you want to process:\n",
    "YOUR_VIDEO_ID = \"put_your_video_id_here\"\n",
    "url = f\"https://www.youtube.com/watch?v={YOUR_VIDEO_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_to_segmented_wavs(url=url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
